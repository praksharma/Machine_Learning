{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight decay\n",
    "This additonal penalty term is L2 regularisation of the weights of the neural networks. Here, our weights can't grow too large and overfit the model. Since, the weights won't grow too large the updation is very small. We don't use L1 regulariser or Lasso regression because we don't want to simplify the neural network by promoting sparsity.\n",
    "$$L(\\mathbf{w}, b) + \\frac{\\lambda}{2} \\|\\mathbf{w}\\|^2$$\n",
    "\n",
    "In the start of the training we might want to have large updates and as we go closer to the global minimum, we want small updates, this can be achieved by using learning rate decay.\n",
    "\n",
    "In pytorch, we can access the weight of `torch.nn` models using `network.weights` and `network.bias`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax regression\n",
    "In classification, there are only two possible outputs, 0 and 1. The Softmax makes sure that the output is nonnegative, usign the exponential terms and the denominator normalises the output between 0 and 1 such that the sum of all outputs is 1. \n",
    "$$\\hat{\\mathbf{y}} = \\mathrm{softmax}(\\mathbf{o}) \\quad \\textrm{where}\\quad \\hat{y}_i = \\frac{\\exp(o_i)}{\\sum_j \\exp(o_j)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Information Theory Basics\n",
    "The central idea in information theory is to quantify the amount of information contained in data. This places a limit on our ability to compress data.\n",
    "### Entropy\n",
    "For a distribution $P$ its entropy H[P] is defined as:\n",
    "\n",
    "$$H[P] = \\sum_j - P(j) \\log P(j)$$\n",
    "\n",
    "If we have more information in the data, for example every single sample has a new pattern, the the entropy is high. Low entropy meaning the data is more predictable and les information-rich.\n",
    "\n",
    "###  Surprisal\n",
    "This is closely related to entropy. A high probably outcome will have low surprisal and vice-versa. For example, filling a fair coin, getting heads in 90% flips has a high surprisal. Mathematically it is measured as \n",
    "$$\\text{Surprisal} = \\log \\frac{1}{P(j)} = -\\log P(j)$$\n",
    "where $j$ is the outcome of an event.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Cross-Entropy\n",
    "Entropy is the level of surprise experienced by someone who knows the true probability. The cross-entropy *from* $P$ *to* $Q$, denoted $H(P, Q)$,\n",
    "is the expected surprisal of an observer with subjective probabilities $Q$\n",
    "This is given by $H(P, Q) \\stackrel{\\textrm{def}}{=} \\sum_j - P(j) \\log Q(j)$. The lowest possible cross-entropy is achieved when $P=Q$. In this case, the cross-entropy from $P$ to $Q$ is $H(P, P)= H(P)$.\n",
    "\n",
    "The cross-entropy classification has two objectives:\n",
    "* maximizing the likelihood of the observed data\n",
    "* minimizing our surprisal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def softmax(X):\n",
    "    X_exp = torch.exp(X)\n",
    "    partition = X_exp.sum(1, keepdims=True)\n",
    "    return X_exp / partition  # The broadcasting mechanism is applied here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2417, 0.2327, 0.1925, 0.1858, 0.1473],\n",
       "         [0.2757, 0.2109, 0.1464, 0.1675, 0.1995]]),\n",
       " tensor([1., 1.]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand((2, 5))\n",
    "X_prob = softmax(X)\n",
    "X_prob, X_prob.sum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modified Softmax\n",
    "Although softmax produced outputs between 0 and 1, when calculating the individual numerator and denominator the computer can result in overflow due to its exponential nature. Thus softmax can be modified to reduce the individual values of the numerator and denominator.\n",
    "\n",
    "$$\\hat y_j = \\frac{\\exp(o_j - \\bar{o})}{\\sum_k \\exp (o_k - \\bar{o})}$$\n",
    "where $$\\bar{o} {=} \\max_k o_k$$ i.e. the maximum value from all entries for that specific sample. By construction, we know that, $$o_j - \\bar{o} \\leq 0$$\n",
    "\n",
    "### RealSoftMax\n",
    "In modified softmax, we can still achieve very large negative values resulting in underflow. To address this, we use  LogSumExp (LSE), or RealSoftMax, or  multivariable softplus. Basically, we combine the computation of softmax and cross-entropy. The essential component of cross-entropy, $\\log\\hat{y}$ can be directly calculated as\n",
    "\n",
    "$$\\log \\hat{y}_j =\n",
    "\\log \\frac{\\exp(o_j - \\bar{o})}{\\sum_k \\exp (o_k - \\bar{o})} =\n",
    "o_j - \\bar{o} - \\log \\sum_k \\exp (o_k - \\bar{o}).$$\n",
    "\n",
    "Here used basic logarithm manipulation to simplify the calculation of $\\log\\hat{y}$ witout seperately calculating the output probabilities of softmax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution shift\n",
    "Sometimes models appear to perform marvelously as measured by test set accuracy but fail catastrophically in deployment when the distribution of data suddenly shifts. Say we trained a model which tells us that the marks of a student in an exam depends on the distance of his house from the school. Sometimes we need to step outside the realm of statistical prediction.\n",
    "\n",
    "### Types of Distribution Shift\n",
    "We assume that our training data was sampled from some distribution $p_S(\\mathbf{x},y)$ and the test data was sampled from some distribution $p_T(\\mathbf{x},y)$. There is no way we can build a robust classifier without knowing any relation between the two distributions. For example, if we train a model to recognise outdoor seasons, and the model was only trained on photos taken in summer then the model will perform poorly on photos taken in winter.\n",
    "\n",
    "#### 1. Covariate Shift\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
